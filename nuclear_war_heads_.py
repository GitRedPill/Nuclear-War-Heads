# -*- coding: utf-8 -*-
"""Nuclear War Heads .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dgAjcziobVe6-hEZ50Ijwl1d9gYcf9u7
"""

# Import
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
file_path = '/content/nuclear_warheads_2023.csv'
data = pd.read_csv(file_path, delimiter=';')

# Display the first few rows of the dataset
print("Last 20 rows of the dataset:")
display(data.tail(20))

# Display basic information

# Display
data.info()

# Check for missing values
print("\nMissing Values:")
print(data.isnull().sum())

# Display summary statistics
print("\nSummary Statistics:")
display(data.describe())

# Display the distribution of categorical columns
categorical_columns = data.select_dtypes(include=['object']).columns
if len(categorical_columns) > 0:
    print("\nCategorical Column Distributions:")
    for col in categorical_columns:
        print(f"\n{col} value counts:")
        print(data[col].value_counts())

#Visual Representation
print("\nHistograms for Numerical Columns:")
data.hist(bins=30, figsize=(15, 10))
plt.tight_layout()
plt.show()

# Box plot to check for outliers in numerical columns
print("\nBox Plots for Numerical Columns:")
for col in data.select_dtypes(include=['number']).columns:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=data[col])
    plt.title(f'Box plot of {col}')
    plt.show()

# Correlation matrix and heatmap
print("\nCorrelation Matrix and Heatmap:")
corr_matrix = data.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

# Scatter plots to explore relationships between pairs of variables
# Example scatter plot between two columns (replace 'variable1' and 'variable2' with actual column names)
if len(data.columns) > 1:
    numerical_columns = data.select_dtypes(include=['number']).columns
    plt.figure(figsize=(8, 6))
    sns.scatterplot(x=numerical_columns[0], y=numerical_columns[1], data=data)
    plt.title(f'Scatter Plot between {numerical_columns[0]} and {numerical_columns[1]}')
    plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Sample data (replace with your actual dataset)
# Assuming 'number_of_nuclear_warheads' is your target variable
data = pd.DataFrame({'year': range(1945, 2024),
                     'number_of_nuclear_warheads': np.random.randint(100, 5000, size=79)})

# Separate features (X) and target variable (y)
X = data.drop('number_of_nuclear_warheads', axis=1)  # Features
y = data['number_of_nuclear_warheads']               # Target variable

# Now both X and y are properly defined, and you won't get the NameError

import matplotlib.pyplot as plt

# Use 'year' for the x-axis and 'number_of_nuclear_warheads' for the y-axis
years = data['year']
nuclear_warheads = data['number_of_nuclear_warheads']

# Create the timeline plot
plt.figure(figsize=(12, 6))
plt.plot(years, nuclear_warheads, marker='o')
plt.xlabel('Year')
plt.ylabel('Number of US Nuclear Warheads')
plt.title('Timeline of US Nuclear Warheads')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Sample data for India (replace with actual data)
data_india = pd.DataFrame({
    'year': range(1945, 2024),
    'number_of_nuclear_warheads': np.random.randint(0, 200, size=79)  # Example data
})

# Use 'year' for the x-axis and 'number_of_nuclear_warheads' for the y-axis
years = data_india['year']
nuclear_warheads = data_india['number_of_nuclear_warheads']

# Create the timeline plot for India
plt.figure(figsize=(12, 6))
plt.plot(years, nuclear_warheads, marker='o', color='orange')  # Optional: color adjustment
plt.xlabel('Year')
plt.ylabel('Number of Indian Nuclear Warheads')
plt.title('Timeline of Indian Nuclear Warheads')
plt.grid(True)
plt.show()

# code for Geomap

import pandas as pd
import plotly.express as px

# Assuming you have a DataFrame with 'Country' and 'Total Warheads' columns


data = pd.DataFrame({
    'Country': ['USA', 'Russia', 'China', 'France', 'UK', 'India', 'Pakistan', 'North Korea', 'Israel'],
    'Total Warheads': [8300, 9800, 650, 320, 345, 230, 210, 55, 95]
})

# Create  map using Plotly Express
fig = px.choropleth(data, locations='Country', locationmode='country names',
                    color='Total Warheads',
                    hover_name='Country',
                    title='Global Distribution of Nuclear Warheads',
                    color_continuous_scale=px.colors.sequential.Plasma)

fig.show()

# Displaying correlations in descending order for insight into strong relationships
print("\nTop Correlations:")
corr_unstacked = corr_matrix.unstack()
sorted_corr = corr_unstacked.sort_values(kind="quicksort", key=abs, ascending=False)
# Filter out self-correlations
strongest_corr = sorted_corr[(abs(sorted_corr) > 0.5) & (abs(sorted_corr) < 1)]
print(strongest_corr)

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import pandas as pd # Import pandas for DataFrame operations

# Sample DataFrame (replace with your actual data loading or creation)
data = pd.DataFrame({'feature1': [1, 2, 3, 4, 5],
                     'feature2': [6, 7, 8, 9, 10],
                     'target_variable': [11, 12, 13, 14, 15]})


# Replace 'target_variable' with the actual name of your target variable column
X = data.drop('target_variable', axis=1)
y = data['target_variable']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the decision tree model
dt_model = DecisionTreeRegressor(random_state=42)

# Train the model
dt_model.fit(X_train, y_train)

# Make predictions
dt_y_pred = dt_model.predict(X_test)

# Evaluate the model
dt_mse = mean_squared_error(y_test, dt_y_pred)
dt_y_pred, dt_mse

# Adjust max depth of the tree
dt_model = DecisionTreeRegressor(max_depth=3, random_state=42)
dt_model.fit(X_train, y_train)

# Make predictions and evaluate
dt_y_pred = dt_model.predict(X_test)
dt_mse = mean_squared_error(y_test, dt_y_pred)

dt_y_pred, dt_mse

from sklearn.ensemble import RandomForestRegressor

#linear regression

X = data.drop('target_variable', axis=1)
y = data['target_variable']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Make predictions
rf_y_pred = rf_model.predict(X_test)

# Evaluate the model
rf_mse = mean_squared_error(y_test, rf_y_pred)

print("Random Forest MSE:", rf_mse)